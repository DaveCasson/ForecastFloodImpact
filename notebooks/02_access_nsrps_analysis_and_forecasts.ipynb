{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access NSRPS Analysis and Forecasts\n",
    "\n",
    "This notebook is used access hydrological data from the Meterological Services Canada WSC Service.\n",
    "This is includes:\n",
    "- Retrieving model analysis\n",
    "- Retrieving deterministic model results\n",
    "- Retrieving ensemble model results\n",
    "\n",
    "It was developed using helpful, open access information provided by [NHS NSRPS Streamflow Tutorials](https://github.com/NHS-Dev/geomet-nsrps-streamflow-tutorials/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import xarray as xr \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Import local scripts\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from nsrps_data_access import query_wms_service_for_forecast_times, query_wms_service_for_analysis_times, query_wcs_service_for_forecast_data,query_wcs_service_for_analysis_data, extract_station_from_grid,bias_correct_forecast\n",
    "from hydrograph_plotting import plot_detailed_hydrograph\n",
    "\n",
    "# Set up logger\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#Suppress info from matplotlib\n",
    "logging.getLogger('matplotlib.category').disabled = True\n",
    "\n",
    "# add autoreload to automatically reload modules when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"../settings/general_settings.yaml\"\n",
    "\n",
    "# Read settings from yaml file\n",
    "with open(config_file, 'r') as ymlfile:\n",
    "    config = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "# Set variables, this can be replaced by a config file. To be discussed\n",
    "api_url = config['msc_open_data_settings']['api_url']\n",
    "\n",
    "# Set up paths \n",
    "gis_data_dir = config['paths']['gis_data']\n",
    "output_base_dir = Path(config['paths']['output_dir'])\n",
    "output_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set up paths to gis data\n",
    "stations_csv = Path(gis_data_dir, config['gis_data']['hydro_stns_csv'])\n",
    "nsrps_station_location_csv = Path(gis_data_dir, config['gis_data']['nsrps_stns_csv'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in login settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading login information\n",
    "login_config = configparser.ConfigParser()\n",
    "login_config.read_file(open('../settings/config.cfg')) \n",
    "\n",
    "login = login_config['Login']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Deterministic Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'DHPS_1km_RiverDischarge'\n",
    "output_dir = Path(output_base_dir, f'{layer_name}')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "newest_fcast, fcasthrs = query_wms_service_for_forecast_times(layer_name, login)\n",
    "forecast_ds = query_wcs_service_for_forecast_data(layer_name, login, newest_fcast, fcasthrs)\n",
    "\n",
    "forecast_ds.to_netcdf(Path(output_dir,f'{newest_fcast}.nc'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in NSRPS stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the list of hydrometric stations\n",
    "nsrps_station_locations_df = pd.read_csv(nsrps_station_location_csv)\n",
    "hydro_stations_df = pd.read_csv(stations_csv)\n",
    "\n",
    "search_stations = hydro_stations_df[\"ID\"].tolist()\n",
    "\n",
    "# Extract the stations that are in the Bow watershed\n",
    "nsrps_stations = nsrps_station_locations_df[nsrps_station_locations_df['STATION_NUMBER'].isin(search_stations)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract forecast data for stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_ds = xr.open_dataset(Path(output_dir,f'{newest_fcast}.nc'))\n",
    "\n",
    "for station in hydro_stations_df.iterrows():\n",
    "\n",
    "    station_data = extract_station_from_grid(station, forecast_ds)\n",
    "    station_data_df = station_data.to_dataframe()\n",
    "    station_data_df.rename(columns={'Band1':'Discharge'}, inplace=True)\n",
    "\n",
    "    station_data_df.to_csv(f'{output_dir}/{station[1][\"ID\"]}_forecast.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download NSRPS Analysis and extract data for stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'DHPS-Analysis_1km_RiverDischarge'\n",
    "output_dir = Path(output_base_dir, f'{layer_name}')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "analysis_time = query_wms_service_for_analysis_times(layer_name, login)\n",
    "\n",
    "analysis_ds = query_wcs_service_for_analysis_data(layer_name, login,analysis_time)\n",
    "\n",
    "analysis_ds.to_netcdf(Path(output_dir,f'{analysis_time}.nc'))\n",
    "\n",
    "for station in hydro_stations_df.iterrows():\n",
    "\n",
    "    station_data = extract_station_from_grid(station, analysis_ds)\n",
    "    station_data_df = station_data.to_dataframe()\n",
    "    station_data_df.rename(columns={'Band1':'Discharge'}, inplace=True)\n",
    "    station_data_df.to_csv(f'{output_dir}/{station[1][\"ID\"]}_analysis.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'DISCHARGE'\n",
    "bias_correct = True\n",
    "\n",
    "\n",
    "real_time_level_stations = nsrps_stations.STATION_NUMBER.values#['05BB001']\n",
    "historic_level_stations = nsrps_stations.STATION_NUMBER.values#['05BB001']\n",
    "\n",
    "for station_id in real_time_level_stations:\n",
    "    if station_id not in historic_level_stations:\n",
    "        continue\n",
    "    \n",
    "    historic_df = pd.read_csv(f'{output_base_dir}/hydrometric-daily-mean/{station_id}_{variable}.csv')\n",
    "    realtime_df = pd.read_csv(f'{output_base_dir}/hydrometric-realtime/{station_id}_{variable}.csv')\n",
    "    analysis_df = pd.read_csv(f'{output_base_dir}/DHPS-Analysis_1km_RiverDischarge/{station_id}_analysis.csv')\n",
    "    forecast_df = pd.read_csv(f'{output_base_dir}/DHPS_1km_RiverDischarge/{station_id}_forecast.csv')\n",
    "    png_path = f'{output_base_dir}/{station_id}_{variable}_forecast_hydrograph.png'\n",
    "\n",
    "    if bias_correct:\n",
    "        forecast_bias_corrected_df = bias_correct_forecast(realtime_df, forecast_df)\n",
    "    else:\n",
    "        forecast_bias_corrected_df = None\n",
    "\n",
    "\n",
    "    plot_detailed_hydrograph(station_id,variable, historic_df, realtime_df, forecast_df, analysis_df,threshold_df=None,forecast_bias_corrected_df=forecast_bias_corrected_df, save_png=True, png_path=png_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def bias_correct(measurements, model):\n",
    "    \n",
    "    # Ensure both dataframes are sorted by index\n",
    "    measurements = measurements.sort_index()\n",
    "    model = model.sort_index()\n",
    "\n",
    "    # Find the last overlapping time\n",
    "    last_overlap_time = measurements.index.intersection(model.index).max()\n",
    "\n",
    "    # If there's no overlap, use the last time of the measurements dataframe\n",
    "    if pd.isna(last_overlap_time):\n",
    "        last_overlap_time = measurements.index[-1]\n",
    "\n",
    "    # Get the last measurement value\n",
    "    last_measurement_value = measurements.loc[last_overlap_time, 'DISCHARGE']\n",
    "\n",
    "    # Get the corresponding model value at the overlap time\n",
    "    if last_overlap_time in model.index:\n",
    "        last_model_value = model.loc[last_overlap_time, 'Discharge']\n",
    "    else:\n",
    "        last_model_value = model.iloc[0]['Discharge']\n",
    "\n",
    "    # Calculate the correction factor\n",
    "    correction_factor = last_measurement_value - last_model_value\n",
    "\n",
    "    # Apply the correction to the model dataframe\n",
    "    model['Discharge'] = model['Discharge'].apply(lambda x: x + correction_factor)\n",
    "\n",
    "    return model\n",
    "\n",
    "test = bias_correct(realtime_df, forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecastfloodimpact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
